{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVTEc    Visualizer\n",
    "\n",
    "- claculates clip embeddings\n",
    "- vizualisation via tensorboard projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: True\n",
      "Torch version: 2.0.1+cu117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 12:08:41.121543: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-23 12:08:41.121571: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-23 12:08:41.121600: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-23 12:08:41.128477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 12:08:41.899060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# activate clip env\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pandas only supports SQLAlchemy connectable.*\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f'GPU is available: {torch.cuda.is_available()}')\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.tensorboard \n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_images_for_tensorboard(image_paths):\n",
    "    # Preprocess the images\n",
    "    transform_display = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(64),  # Resize the images \n",
    "        torchvision.transforms.CenterCrop(64),  # Crop the images\n",
    "        torchvision.transforms.ToTensor()  # Convert images to tensors        \n",
    "    ])\n",
    "\n",
    "    images = []  # Array to store the preprocessed images\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path).convert('RGB')  # Open the image and convert to RGB\n",
    "        # Apply the display transformation\n",
    "        image_display = transform_display(image)\n",
    "        image_display = image_display.unsqueeze(0) # Add a batch dimension to the image\n",
    "        images.append(image_display)\n",
    "\n",
    "    images = torch.cat(images, dim=0)  # Concatenate the images along the batch dimension\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHs\n",
    "PROJECT_DATA_PATH='/home/bule/projects/Transformaly_FUAD/data/mvtec_anomaly_detection'\n",
    "LOG_DIR= '/home/bule/projects/Transformaly_FUAD/tensorboard_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5354"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paths to images\n",
    "image_paths = []\n",
    "for root, dirs, files in os.walk(PROJECT_DATA_PATH):\n",
    "    if 'ground_truth' not in root:\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "len(image_paths)\n",
    "## TODO embedd all images from MVTEC in CLIP space\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/home/bule/projects/Transformaly_FUAD/data/mvtec_anomaly_detection/pill/train/good/058.png</th>\n",
       "      <td>-0.255127</td>\n",
       "      <td>-0.003624</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.293213</td>\n",
       "      <td>0.319824</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.131104</td>\n",
       "      <td>0.075317</td>\n",
       "      <td>0.072937</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.422119</td>\n",
       "      <td>0.032654</td>\n",
       "      <td>-0.417236</td>\n",
       "      <td>-0.247314</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>-0.308350</td>\n",
       "      <td>0.668945</td>\n",
       "      <td>0.321045</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/bule/projects/Transformaly_FUAD/data/mvtec_anomaly_detection/pill/train/good/065.png</th>\n",
       "      <td>-0.144531</td>\n",
       "      <td>-0.184204</td>\n",
       "      <td>0.286377</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>-0.159668</td>\n",
       "      <td>0.058960</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032013</td>\n",
       "      <td>0.256592</td>\n",
       "      <td>-0.087402</td>\n",
       "      <td>-0.712402</td>\n",
       "      <td>-0.010551</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>0.491943</td>\n",
       "      <td>-0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/bule/projects/Transformaly_FUAD/data/mvtec_anomaly_detection/pill/train/good/173.png</th>\n",
       "      <td>-0.311279</td>\n",
       "      <td>-0.250977</td>\n",
       "      <td>0.210327</td>\n",
       "      <td>0.214722</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>0.077942</td>\n",
       "      <td>-0.134033</td>\n",
       "      <td>0.241943</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>-0.167847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159424</td>\n",
       "      <td>0.445801</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>-0.574707</td>\n",
       "      <td>0.131104</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>-0.070374</td>\n",
       "      <td>0.660156</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>-0.256104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/bule/projects/Transformaly_FUAD/data/mvtec_anomaly_detection/pill/train/good/044.png</th>\n",
       "      <td>-0.166626</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.190674</td>\n",
       "      <td>0.383789</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.236084</td>\n",
       "      <td>0.219971</td>\n",
       "      <td>-0.086060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129639</td>\n",
       "      <td>0.190063</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>-0.464600</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>-0.088989</td>\n",
       "      <td>0.745117</td>\n",
       "      <td>0.257080</td>\n",
       "      <td>-0.310547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/bule/projects/Transformaly_FUAD/data/mvtec_anomaly_detection/pill/train/good/175.png</th>\n",
       "      <td>-0.186401</td>\n",
       "      <td>-0.187744</td>\n",
       "      <td>0.048248</td>\n",
       "      <td>0.418213</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.156372</td>\n",
       "      <td>0.259521</td>\n",
       "      <td>0.132690</td>\n",
       "      <td>0.138916</td>\n",
       "      <td>-0.100769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267090</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>-0.426025</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>0.278564</td>\n",
       "      <td>-0.290771</td>\n",
       "      <td>0.668457</td>\n",
       "      <td>0.419434</td>\n",
       "      <td>-0.028442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1    \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.255127 -0.003624   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.144531 -0.184204   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.311279 -0.250977   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.166626 -0.156250   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.186401 -0.187744   \n",
       "\n",
       "                                                         2         3    \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.163086  0.293213   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.286377  0.187256   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.210327  0.214722   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.235596  0.190674   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.048248  0.418213   \n",
       "\n",
       "                                                         4         5    \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.319824  0.009521   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.088867 -0.159668   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.283203  0.077942   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.383789  0.034058   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.122986  0.156372   \n",
       "\n",
       "                                                         6         7    \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.131104  0.075317   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.058960  0.182617   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.134033  0.241943   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.002312  0.236084   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.259521  0.132690   \n",
       "\n",
       "                                                         8         9    ...  \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.072937  0.185791  ...   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.172485  0.022232  ...   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.173828 -0.167847  ...   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.219971 -0.086060  ...   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.138916 -0.100769  ...   \n",
       "\n",
       "                                                         502       503  \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.122559  0.422119   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.032013  0.256592   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.159424  0.445801   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.129639  0.190063   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.267090  0.516602   \n",
       "\n",
       "                                                         504       505  \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.032654 -0.417236   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.087402 -0.712402   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.003481 -0.574707   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.038422 -0.464600   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.001023 -0.426025   \n",
       "\n",
       "                                                         506       507  \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.247314  0.374512   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.010551  0.552734   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.131104  0.278076   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.044800  0.020004   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.120300  0.278564   \n",
       "\n",
       "                                                         508       509  \\\n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.308350  0.668945   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.027878  0.615723   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.070374  0.660156   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.088989  0.745117   \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte... -0.290771  0.668457   \n",
       "\n",
       "                                                         510       511  \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.321045  0.006065  \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.491943 -0.000437  \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.447266 -0.256104  \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.257080 -0.310547  \n",
       "/home/bule/projects/Transformaly_FUAD/data/mvte...  0.419434 -0.028442  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1024  # Adjust this based on your GPU memory\n",
    "FILENAME = 'MVTEC_embeddings_df'\n",
    "\n",
    "if not os.path.exists(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl')):\n",
    "\n",
    "    # Load the model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, transform = clip.load('ViT-B/32', device=device)\n",
    "\n",
    "\n",
    "    # Function to get embeddings for a batch of images\n",
    "    def get_batch_embeddings(batch_paths):\n",
    "        images = [Image.open(p) for p in batch_paths]\n",
    "        tensors = [transform(img) for img in images]\n",
    "        batch_tensor = torch.stack(tensors).to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_features = model.encode_image(batch_tensor)\n",
    "        return batch_features.cpu().numpy()\n",
    "\n",
    "    # Calculate embeddings for all images in batches\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(image_paths), BATCH_SIZE):\n",
    "        batch_paths = image_paths[i:i+BATCH_SIZE]\n",
    "        batch_embeddings = get_batch_embeddings(batch_paths)\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "        print(f\"Processed images {i} to {i + len(batch_embeddings)}\")\n",
    "\n",
    "    # Convert all embeddings to DataFrame and save\n",
    "    df = pd.DataFrame(all_embeddings, index=image_paths)\n",
    "    df.to_pickle(os.path.join(PROJECT_DATA_PATH, FILENAME + '.pkl'))\n",
    "else:\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVTEC_embeddings_df\n",
      "MVTEC_embeddings_df  number of images:5354\n"
     ]
    }
   ],
   "source": [
    "# make tensorboard logs\n",
    "\n",
    "print(FILENAME)\n",
    "TENSORBOARD_LOGS_PATH=os.path.join(LOG_DIR,'_'+FILENAME).replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "if not  os.path.exists(TENSORBOARD_LOGS_PATH):\n",
    "\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "\n",
    "    # Convert the resulting series of lists to a NumPy array\n",
    "    numpy_array = df.to_numpy()\n",
    "\n",
    "    # resize images \n",
    "    images = convert_images_for_tensorboard(image_paths)\n",
    "\n",
    "    # for tensorboard\n",
    "    writer = SummaryWriter(TENSORBOARD_LOGS_PATH)\n",
    "    writer.add_embedding(numpy_array, label_img=images)\n",
    "\n",
    "else:\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "\n",
    "print(f'{FILENAME}  number of images:{len(image_paths)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run tensorboard on port forward to browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-23 12:09:07.193446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-23 12:09:07.193486: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-23 12:09:07.193526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-23 12:09:07.205167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 12:09:08.241029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-23 12:09:09.443824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 12:09:09.456780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-23 12:09:09.457051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard  --logdir $TENSORBOARD_LOGS_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformalyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
